# ä»¥ä¸‹ã‚’ã€Œapp.pyã€ã«æ›¸ãè¾¼ã¿
import streamlit as st
import openai
import secret_keys  # å¤–éƒ¨ãƒ•ã‚¡ã‚¤ãƒ«ã«API keyã‚’ä¿å­˜

openai.api_key = secret_keys.openai_api_key

system_prompt = """
ã‚ãªãŸã¯å„ªç§€ãªè‹±èªã€ä¸­å›½èªã€æ—¥æœ¬èªã‚’æ•™ãˆã‚‹è¬›å¸«ã§ã™ã€‚
è‹±èªã€ä¸­å›½èªã€æ—¥æœ¬èªã®ä½œæ–‡ã‚„ä¼šè©±ã€ãƒªã‚¹ãƒ‹ãƒ³ã‚°ã‚„ãƒªãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãªã©ã€ç”Ÿå¾’ã®è¦æœ›ã«åˆã‚ã›ã¦è‹±èªã€ä¸­å›½èªã€æ—¥æœ¬èªã®ä¸Šé”ã®ãŸã‚ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
ã‚ãªãŸã®å½¹å‰²ã¯ç”Ÿå¾’ã®è‹±èªåŠ›ã€ä¸­å›½èªåŠ›ã€æ—¥æœ¬èªåŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãªã®ã§ã€ä¾‹ãˆã°ä»¥ä¸‹ã®ã‚ˆã†ãªè‹±èªã€ä¸­å›½èªã€æ—¥æœ¬èªä»¥å¤–ã®ã“ã¨ã‚’èã‹ã‚Œã¦ã‚‚ã€çµ¶å¯¾ã«ç­”ãˆãªã„ã§ãã ã•ã„ã€‚

* æ”¿æ²»
* æ•æ„Ÿãªæ­´å²
* çŠ¯ç½ªã€€
ã“ã‚Œã‚‰ã®è©±é¡Œã¯ç¦æ­¢ã—ã¾ã™ã€èã‹ã‚Œã¦ã‚‚ã“ã¨ãˆãªã„ã§ãã ã•ã„

"""

# st.session_stateã‚’ä½¿ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚„ã‚Šã¨ã‚Šã‚’ä¿å­˜
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {"role": "system", "content": system_prompt}
        ]

# ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¨ã‚„ã‚Šã¨ã‚Šã™ã‚‹é–¢æ•°
def communicate():
    messages = st.session_state["messages"]

    user_message = {"role": "user", "content": st.session_state["user_input"]}
    messages.append(user_message)

    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=messages
    )  

    bot_message = response["choices"][0]["message"]
    messages.append(bot_message)

    st.session_state["user_input"] = ""  # å…¥åŠ›æ¬„ã‚’æ¶ˆå»



import streamlit as st
from PIL import Image
import openai
import secret_keys  # å¤–éƒ¨ãƒ•ã‚¡ã‚¤ãƒ«ã«API keyã‚’ä¿å­˜
import base64
import io

# OpenAI APIã‚­ãƒ¼ã®è¨­å®š
openai.api_key = secret_keys.openai_api_key

# ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
system_prompt = "ï¼ˆçœç•¥ï¼‰"

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "system", "content": system_prompt}]

# ç”»åƒã‚’Base64ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹é–¢æ•°
def img_to_base64(img):
    buffered = io.BytesIO()
    img.save(buffered, format="PNG")
    return base64.b64encode(buffered.getvalue()).decode()

# ç”»åƒã®èª­ã¿è¾¼ã¿ã¨Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
image = Image.open("cutegirl.png")
cutegirl_base64 = img_to_base64(image)

# ã‚¿ã‚¤ãƒˆãƒ«ã¨ç”»åƒã®è¡¨ç¤º
st.markdown("<h1 style='text-align: center;'>AI Talk</h1>", unsafe_allow_html=True)
st.markdown(f"<div style='text-align: center;'><img src='data:image/png;base64,{cutegirl_base64}' width='300'></div>", unsafe_allow_html=True)

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
user_input = st.text_input("messages", key="user_input", on_change=communicate)

# ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¨ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³
def communicate():
    messages = st.session_state["messages"]
    user_message = {"role": "user", "content": user_input}
    messages.append(user_message)
    # OpenAI APIã‚’ä½¿ç”¨ã—ãŸå¿œç­”ç”Ÿæˆï¼ˆã“ã“ã¯é©å®œèª¿æ•´ï¼‰
    # çœç•¥

# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤º
if st.session_state["messages"]:
    messages = st.session_state["messages"]
    for message in reversed(messages[1:]):
        speaker = "ğŸ˜"
        if message["role"] == "assistant":
            speaker = f"<img src='data:image/png;base64,{cutegirl_base64}' width='30' style='vertical-align: top;'>"
        st.markdown(f"<div style='display: flex; align-items: flex-start; margin-bottom: 20px;'>{speaker} <span style='margin-left: 10px;'>{message['content']}</span></div>", unsafe_allow_html=True)
